<!DOCTYPE html>
<head>
    <title>Project 2: Fun with Filters and Frequencies!</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Poppins', sans-serif;
            line-height: 1.6;
            margin: 0 auto;
            max-width: 960px;
            padding: 20px;
        }

        .gallery-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 10px;
        }
        
        .gallery-item {
            text-align: center;
        }

        .gallery-item img {
            width: 80%;
            height: 70%; 
            object-fit: cover;
            border-radius: 5px;
            background-color: #eee;
        }

        .gallery-item p {
            margin-top: 5px;
            font-size: 1em;
            color: #6c6464;
        }

        h1, h2, h3, h4 {
            color: #333;
        }

        ul {
            list-style-type: disc;
            padding-left: 20px;
        }

        li {
            margin-bottom: 10px;
        }

        .button {
            display: inline-block;
            padding: 10px 20px;
            font-size: 16px;
            font-weight: 600;
            text-align: center;
            cursor: pointer;
            border: none;
            border-radius: 5px;
            background-color: #101256;
            color: white;
            transition: background-color 0.3s ease;
        }
        
        .button:hover {
            background-color: #63dac4;
        }

        .images img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
    </style>
</head>
<body>
    <a href="../index.html">
        <button class="button">home</button>
    </a>
    <h1>Project 2: Fun with Filters and Frequencies!</h1>
    <hr>

    <h2>Part 1: Fun with Filters</h2>

    <h3>1.1: Convolutions from Scratch!</h3>
    <p>For 1.1, I implemented 2D convolution from scratch in NumPy, first using four loops and then optimizing it with two loops with padding. I validated it by comparing its output with scipy.signal.convolve2d, then applied it to a grayscale photo using a 9×9 box filter and then the finite difference operators dx and dy. </p>
    <p> Convolution with four for loops code:</p>
    <pre><code>def convolve_4_loops(image, kernel):
    kh, kw = kernel.shape
    pad_h = kh // 2
    pad_w = kw // 2
    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w))) 
    output = np.zeros_like(image)
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            for m in range(kh):
                for n in range(kw):
                    output[i, j] += padded[i + m, j + n] * kernel[m, n]
    return output</code></pre>
    <p> Convolution with two for loops code:</p>
    <pre><code>def convolve_2_loops(image, kernel):
    kh, kw = kernel.shape
    pad_h = kh // 2
    pad_w = kw // 2
    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)))
    output = np.zeros_like(image)
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            patch = padded[i:i+kh, j:j+kw]
            output[i, j] = np.sum(patch * kernel)
    return output</code></pre>
    <p> The two-loop version runs significantly faster than the four-loop one due to reduced nested functions and the use of np for kernel multiplication and summation. Both custom functions produced results identical to scipy.signal.convolve2d. However, convolve2d is still the fastest. For boundary handling, my functions used zero-padding np.pad(). Convolve2d also offers more flexible boundary options like "symm" or "wrap".</p>
    <p> Custom function Image result: </p>
    <div class="images">
        <img src="web/result/1.1.png" alt="1.1">
    </div>
    
    <h3>1.2: Finite Difference Operation</h3>
    <p>To detect edges, I applied the finite difference operators Dx and Dy to the “cameraman” image using scipy.signal.convolve2d. The horizontal and vertical gradients (Gx and Gy) were combined into a gradient magnitude map G via the Pythagorean theorem. After experimenting, T = 0.3 produced a clean binary edge map that suppresses noise showing all the real edges.</p>
     <div class="images">
        <img src="web/result/1.2.png" alt="1.2">
    </div>
    
    <h3>1.3: Derivative of Gaussian (DoG) Filters</h3>
    <p>Next, I explored smoothing with a Gaussian filter. I generated a 2D Gaussian kernel using cv2.getGaussianKernel() and applied it to the image before computing derivatives. The resulting edges were thicker and cleaner than with the raw finite difference method because the Gaussian filter suppresses high-frequency noise.
I then combined smoothing and differentiation into a single convolution by constructing Derivative-of-Gaussian (DoG) filters (Gx = G * Dx, Gy = G * Dy). Convolution with these DoG kernels produced the same results as the two-step process, showing the associative property of convolution: I * (G * Dx) = (I * G) * Dx. This approach results in the same clean, smoothed gradients but with more efficiency. 
</p> 
    <div class="images">
        <img src="web/result/1.3.png" alt="1.3">
    </div>

    <h2>Part 2: Fun with Frequencies</h2>
    
    <h3>2.1: Image "Sharpening"</h3>
<p>Sharpening works by boosting the high-frequency components of an image, typically using the unsharp mask filter. I did this through:</p>    <ul>
        <li>Blur the original image to get low pass</li>
        <li>Subtract the blurred image from the original to isolate high frequencies (HF)</li>
        <li>Add high frequencies (alpha * HF) back to the original to get the sharpened image</li>    </ul>
    <p> I tested it on the Taj Mahal image with a Gaussian kernel. As the scaling factor alpha increased, the edges became more obvious, but it also produced unnatural rings around the high contrast areas. This shows that this sharpening process amplifies detail but cannot restore information lost from blurring. </p>
     <div class="images">
        <img src="web/result/2.1_taj.png" alt="2.1">
        <img src="web/result/2.1_drink.png" alt="2.1">
    </div>
    
    <h3>2.2: Hybrid Images</h3>
<p>Hybrid images combine the low frequencies of one image with the high frequencies of another to create a composite that changes appearance based on viewing distance. I implemented this by:</p>
</p>

<p>I created the hybrid image by blending a low-pass filtered (LPF) image with a high-pass filtered (HPF) image. To implement this:</p>
    <ul>
        <li>Extracting low frequencies from the first image using a Gaussian filter</li>
        <li>Extracting high frequencies from the second image by subtracting its blurred version from the original</li>
        <li>add the low and high filtered images to create the hybrid image</li>
    <div class="gallery-grid">
        <div class="gallery-item">
            <img src="web/result/2.2_nutmeg.jpg" alt="emir">
            <p>Nutmeg</p>
        </div>
        <div class="gallery-item">
            <img src="web/result/2.2_DerekPicture.jpg" alt="emir">
            <p>Derek</p>
        </div>
        <div class="gallery-item">
            <img src="web/result/2.2_derek_15_9.jpg" alt="emir">
            <p>Hybrid</p>
        </div>
    </div>

    <div class="gallery-grid">
        <div class="gallery-item">
            <img src="web/result/2.2_hybrid_lilo.jpg" alt="emir">
            <p>Lilo</p>
        </div>
        <div class="gallery-item">
            <img src="web/result/2.2_hybrid_stitch.jpg" alt="emir">
            <p>Stitch</p>
        </div>
        <div class="gallery-item">
            <img src="web/result/2.2_lilo_15_20.jpg" alt="emir">
            <p>Hybrid</p>
        </div>
    </div>

    <div class="gallery-grid">
        <div class="gallery-item">
            <img src="web/result/2.2_hybrid_wednesday.jpg" alt="emir">
            <p>Wednesday</p>
        </div>
        <div class="gallery-item">
            <img src="web/result/2.2_hybrid_enid.jpg" alt="emir">
            <p>Enid</p>
        </div>
        <div class="gallery-item">
            <img src="web/result/2.2_wed_20_15.jpg" alt="emir">
            <p>Hybrid</p>
        </div>
    </div>
    <div class="images">
        <img src="web/result/2.2_hybrid_wed_process.png" alt="2.2">
    </div>
    <h4> Fourier Transforms</h4>
    <p> The low-pass filtered image's FFT shows energy concentrated in the center (low frequencies), while the high-pass filtered image's FFT shows energy concentrated in the outer regions (high frequencies). The resulting hybrid FFT spectrum is a combination of these two. </p>

    <h3>2.3 + 2.4: Gaussian and Laplacian Stacks and Multiresolution Blending</h3>
<p>Gaussian Stack: Each level of the stack is created by applying a Gaussian filter with increasing sigma values. This produces progressively smoother versions of the original image, capturing the image at different scales of detail.</p>
<p>Laplacian Stack: Each Laplacian layer represents the details lost between successive Gaussian layers. It is computed as: L_i = G_i - G_{i+1} This isolates the high-frequency content at each level.
</p>
<p> Stacks are useful for blending because they allow us to separately manipulate low-frequency and high-frequency components without changing the image size. Initially, I used a vertical step mask with values 1 on the left and 0 on the right, but simply smoothing the mask with a Gaussian did not sufficiently eliminate the seam. Only a small region near the boundary changed, leaving a visible hard edge. After adjusting the mask to transition smoothly from 1 to 0 across a wider region, the blended images became seamless. I got this idea from an anonymous commenter on ed. I also tried blending with an irregular mask, specifically a circular mask. The Gaussian stack of the circular mask ensures the transition zone is smooth even along a curved edge.
</p>
<div class="images">
        <img src="web/result/2.3_Gaussian_Laplacian.png" alt="2.2">
        <img src="web/result/2.3_pyramid_stack.png" alt="2.2">
    </div>

    <h4>Additional Blended Images</h4>

    <div class="images">
        <img src="web/result/2.4_clock.png" alt="2.2">
        <p> clock with vertical seam</p>
        <img src="web/result/2.4_sun.png" alt="2.2">
        <p> sun and moon with circle mask </p>
    </div>

    <h3> Takeaway</h3>
    <p> One of the most interesting things I learned in this project was how manipulating different frequency components of an image can drastically change what we perceive. It was fascinating to see how high-frequency details show up when viewing an image up close, but at a distance, our eyes are drawn to the low-frequency components.</p>
    <hr>
</body>
</html>
